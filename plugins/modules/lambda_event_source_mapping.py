#!/usr/bin/python
# -*- coding: utf-8 -*-
# Copyright: (c) 2022, Ansible Project
# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt)
# template: header.j2
# This module is autogenerated using the gouttelette generator tool
# See: https://github.com/ansible-collections/gouttelette


DOCUMENTATION = r"""
module: lambda_event_source_mapping
short_description: Create a mapping between an event source and an AWS Lambda function
description:
- Create a mapping between an event source and an AWS Lambda function.
options:
    amazon_managed_kafka_event_source_config:
        description:
        - Specific configuration settings for an MSK event source.Specific configuration
            settings for an MSK event source.
        suboptions:
            consumer_group_id:
                description:
                - The identifier for the Kafka Consumer Group to join.The identifier
                    for the Kafka Consumer Group to join.
                type: str
        type: dict
    batch_size:
        description:
        - The maximum number of items to retrieve in a single batch.
        type: int
    bisect_batch_on_function_error:
        description:
        - (Streams) If the function returns an error, split the batch in two and retry.
        type: bool
    destination_config:
        description:
        - (Streams) An Amazon SQS queue or Amazon SNS topic destination for discarded
            records.(Streams) An Amazon SQS queue or Amazon SNS topic destination
            for discarded records.
        suboptions:
            on_failure:
                description:
                - The destination configuration for failed invocations.A destination
                    for events that failed processing.
                suboptions:
                    destination:
                        description:
                        - The Amazon Resource Name (ARN) of the destination resource.
                        type: str
                type: dict
        type: dict
    enabled:
        description:
        - Disables the event source mapping to pause polling and invocation.
        type: bool
    event_source_arn:
        description:
        - The Amazon Resource Name (ARN) of the event source.
        type: str
    filter_criteria:
        description:
        - The filter criteria to control event filtering.The filter criteria to control
            event filtering.
        suboptions:
            filters:
                description:
                - The filter object that defines parameters for ESM filtering.
                elements: dict
                suboptions:
                    pattern:
                        description:
                        - The filter pattern that defines which events should be passed
                            for invocations.
                        type: str
                type: list
        type: dict
    force:
        default: false
        description:
        - Cancel IN_PROGRESS and PENDING resource requestes.
        - Because you can only perform a single operation on a given resource at a
            time, there might be cases where you need to cancel the current resource
            operation to make the resource available so that another operation may
            be performed on it.
        type: bool
    function_name:
        description:
        - The name of the Lambda function.
        type: str
    function_response_types:
        choices:
        - ReportBatchItemFailures
        description:
        - (Streams) A list of response types supported by the function.
        elements: str
        type: list
    id:
        description:
        - Event Source Mapping Identifier UUID.
        type: str
    maximum_batching_window_in_seconds:
        description:
        - (Streams) The maximum amount of time to gather records before invoking the
            function, in seconds.
        type: int
    maximum_record_age_in_seconds:
        description:
        - (Streams) The maximum age of a record that Lambda sends to a function for
            processing.
        type: int
    maximum_retry_attempts:
        description:
        - (Streams) The maximum number of times to retry when the function returns
            an error.
        type: int
    parallelization_factor:
        description:
        - (Streams) The number of batches to process from each shard concurrently.
        type: int
    queues:
        description:
        - (ActiveMQ) A list of ActiveMQ queues.
        elements: str
        type: list
    scaling_config:
        description:
        - The scaling configuration for the event source.The scaling configuration
            for the event source.
        suboptions:
            maximum_concurrency:
                description:
                - The maximum number of concurrent functions that the event source
                    can invoke.The maximum number of concurrent functions that an
                    event source can invoke.
                type: int
        type: dict
    self_managed_event_source:
        description:
        - Self-managed event source endpoints.The configuration used by AWS Lambda
            to access a self-managed event source.
        suboptions:
            endpoints:
                description:
                - The endpoints for a self-managed event source.The endpoints used
                    by AWS Lambda to access a self-managed event source.
                suboptions:
                    kafka_bootstrap_servers:
                        description:
                        - The URL of a Kafka server.
                        elements: str
                        type: list
                type: dict
        type: dict
    self_managed_kafka_event_source_config:
        description:
        - Specific configuration settings for a Self-Managed Apache Kafka event source.Specific
            configuration settings for a Self-Managed Apache Kafka event source.
        suboptions:
            consumer_group_id:
                description:
                - The identifier for the Kafka Consumer Group to join.
                type: str
        type: dict
    source_access_configurations:
        description:
        - The configuration used by AWS Lambda to access event source.
        elements: dict
        suboptions:
            type:
                choices:
                - BASIC_AUTH
                - CLIENT_CERTIFICATE_TLS_AUTH
                - SASL_SCRAM_256_AUTH
                - SASL_SCRAM_512_AUTH
                - SERVER_ROOT_CA_CERTIFICATE
                - VIRTUAL_HOST
                - VPC_SECURITY_GROUP
                - VPC_SUBNET
                description:
                - The type of source access configuration.
                type: str
            uri:
                description:
                - The URI for the source access configuration resource.
                type: str
        type: list
    starting_position:
        description:
        - The position in a stream from which to start reading.
        - Required for Amazon Kinesis and Amazon DynamoDB Streams sources.
        type: str
    starting_position_timestamp:
        description:
        - With StartingPosition set to C(AT_TIMESTAMP), the time from which to start
            reading, in Unix time seconds.
        type: int
    state:
        choices:
        - present
        - absent
        - list
        - describe
        - get
        default: present
        description:
        - Goal state for resource.
        - I(state=present) creates the resource if it doesn't exist, or updates to
            the provided state if the resource already exists.
        - I(state=absent) ensures an existing instance is deleted.
        - I(state=list) get all the existing resources.
        - I(state=describe) or I(state=get) retrieves information on an existing resource.
        type: str
    topics:
        description:
        - (Kafka) A list of Kafka topics.
        elements: str
        type: list
    tumbling_window_in_seconds:
        description:
        - (Streams) Tumbling window (non-overlapping time window) duration to perform
            aggregations.
        type: int
    wait:
        default: false
        description:
        - Wait for operation to complete before returning.
        type: bool
    wait_timeout:
        default: 320
        description:
        - How many seconds to wait for an operation to complete before timing out.
        type: int
author: Ansible Cloud Team (@ansible-collections)
version_added: 0.1.0
extends_documentation_fragment:
- amazon.aws.aws
- amazon.aws.ec2
- amazon.cloud.boto3
"""

EXAMPLES = r"""
"""

RETURN = r"""
result:
    description:
        - When I(state=list), it is a list containing dictionaries of resource information.
        - Otherwise, it is a dictionary of resource information.
        - When I(state=absent), it is an empty dictionary.
    returned: always
    type: complex
    contains:
        identifier:
            description: The unique identifier of the resource.
            type: str
        properties:
            description: The resource properties.
            type: dict
"""


from ansible_collections.amazon.cloud.plugins.module_utils.core import (
    AnsibleAmazonCloudModule,
)
from ansible_collections.amazon.cloud.plugins.module_utils.core import (
    CloudControlResource,
)
from ansible_collections.amazon.cloud.plugins.module_utils.core import (
    snake_dict_to_camel_dict,
)
from ansible_collections.amazon.cloud.plugins.module_utils.core import (
    ansible_dict_to_boto3_tag_list,
)


def main():
    argument_spec = dict(
        state=dict(
            type="str",
            choices=["present", "absent", "list", "describe", "get"],
            default="present",
        ),
    )

    argument_spec["id"] = {"type": "str"}
    argument_spec["batch_size"] = {"type": "int"}
    argument_spec["bisect_batch_on_function_error"] = {"type": "bool"}
    argument_spec["destination_config"] = {
        "type": "dict",
        "options": {
            "on_failure": {"type": "dict", "options": {"destination": {"type": "str"}}}
        },
    }
    argument_spec["enabled"] = {"type": "bool"}
    argument_spec["event_source_arn"] = {"type": "str"}
    argument_spec["filter_criteria"] = {
        "type": "dict",
        "options": {
            "filters": {
                "type": "list",
                "elements": "dict",
                "options": {"pattern": {"type": "str"}},
            }
        },
    }
    argument_spec["function_name"] = {"type": "str"}
    argument_spec["maximum_batching_window_in_seconds"] = {"type": "int"}
    argument_spec["maximum_record_age_in_seconds"] = {"type": "int"}
    argument_spec["maximum_retry_attempts"] = {"type": "int"}
    argument_spec["parallelization_factor"] = {"type": "int"}
    argument_spec["starting_position"] = {"type": "str"}
    argument_spec["starting_position_timestamp"] = {"type": "int"}
    argument_spec["topics"] = {"type": "list", "elements": "str"}
    argument_spec["queues"] = {"type": "list", "elements": "str"}
    argument_spec["source_access_configurations"] = {
        "type": "list",
        "elements": "dict",
        "options": {
            "type": {
                "type": "str",
                "choices": [
                    "BASIC_AUTH",
                    "CLIENT_CERTIFICATE_TLS_AUTH",
                    "SASL_SCRAM_256_AUTH",
                    "SASL_SCRAM_512_AUTH",
                    "SERVER_ROOT_CA_CERTIFICATE",
                    "VIRTUAL_HOST",
                    "VPC_SECURITY_GROUP",
                    "VPC_SUBNET",
                ],
            },
            "uri": {"type": "str"},
        },
    }
    argument_spec["tumbling_window_in_seconds"] = {"type": "int"}
    argument_spec["function_response_types"] = {
        "type": "list",
        "elements": "str",
        "choices": ["ReportBatchItemFailures"],
    }
    argument_spec["self_managed_event_source"] = {
        "type": "dict",
        "options": {
            "endpoints": {
                "type": "dict",
                "options": {
                    "kafka_bootstrap_servers": {"type": "list", "elements": "str"}
                },
            }
        },
    }
    argument_spec["amazon_managed_kafka_event_source_config"] = {
        "type": "dict",
        "options": {"consumer_group_id": {"type": "str"}},
    }
    argument_spec["self_managed_kafka_event_source_config"] = {
        "type": "dict",
        "options": {"consumer_group_id": {"type": "str"}},
    }
    argument_spec["scaling_config"] = {
        "type": "dict",
        "options": {"maximum_concurrency": {"type": "int"}},
    }
    argument_spec["state"] = {
        "type": "str",
        "choices": ["present", "absent", "list", "describe", "get"],
        "default": "present",
    }
    argument_spec["wait"] = {"type": "bool", "default": False}
    argument_spec["wait_timeout"] = {"type": "int", "default": 320}
    argument_spec["force"] = {"type": "bool", "default": False}

    required_if = [
        ["state", "present", ["id", "function_name"], True],
        ["state", "absent", ["id"], True],
        ["state", "get", ["id"], True],
    ]
    mutually_exclusive = []

    module = AnsibleAmazonCloudModule(
        argument_spec=argument_spec,
        required_if=required_if,
        mutually_exclusive=mutually_exclusive,
        supports_check_mode=True,
    )
    cloud = CloudControlResource(module)

    type_name = "AWS::Lambda::EventSourceMapping"

    params = {}

    params["amazon_managed_kafka_event_source_config"] = module.params.get(
        "amazon_managed_kafka_event_source_config"
    )
    params["batch_size"] = module.params.get("batch_size")
    params["bisect_batch_on_function_error"] = module.params.get(
        "bisect_batch_on_function_error"
    )
    params["destination_config"] = module.params.get("destination_config")
    params["enabled"] = module.params.get("enabled")
    params["event_source_arn"] = module.params.get("event_source_arn")
    params["filter_criteria"] = module.params.get("filter_criteria")
    params["function_name"] = module.params.get("function_name")
    params["function_response_types"] = module.params.get("function_response_types")
    params["id"] = module.params.get("id")
    params["maximum_batching_window_in_seconds"] = module.params.get(
        "maximum_batching_window_in_seconds"
    )
    params["maximum_record_age_in_seconds"] = module.params.get(
        "maximum_record_age_in_seconds"
    )
    params["maximum_retry_attempts"] = module.params.get("maximum_retry_attempts")
    params["parallelization_factor"] = module.params.get("parallelization_factor")
    params["queues"] = module.params.get("queues")
    params["scaling_config"] = module.params.get("scaling_config")
    params["self_managed_event_source"] = module.params.get("self_managed_event_source")
    params["self_managed_kafka_event_source_config"] = module.params.get(
        "self_managed_kafka_event_source_config"
    )
    params["source_access_configurations"] = module.params.get(
        "source_access_configurations"
    )
    params["starting_position"] = module.params.get("starting_position")
    params["starting_position_timestamp"] = module.params.get(
        "starting_position_timestamp"
    )
    params["topics"] = module.params.get("topics")
    params["tumbling_window_in_seconds"] = module.params.get(
        "tumbling_window_in_seconds"
    )

    # The DesiredState we pass to AWS must be a JSONArray of non-null values
    _params_to_set = {k: v for k, v in params.items() if v is not None}

    # Only if resource is taggable
    if module.params.get("tags") is not None:
        _params_to_set["tags"] = ansible_dict_to_boto3_tag_list(module.params["tags"])

    params_to_set = snake_dict_to_camel_dict(_params_to_set, capitalize_first=True)

    # Ignore createOnlyProperties that can be set only during resource creation
    create_only_params = [
        "event_source_arn",
        "starting_position",
        "starting_position_timestamp",
        "self_managed_event_source",
        "amazon_managed_kafka_event_source_config",
        "self_managed_kafka_event_source_config",
    ]

    # Necessary to handle when module does not support all the states
    handlers = ["create", "delete", "list", "read", "update"]

    state = module.params.get("state")
    identifier = ["id"]

    results = {"changed": False, "result": {}}

    if state == "list":
        if "list" not in handlers:
            module.exit_json(
                **results, msg=f"Resource type {type_name} cannot be listed."
            )
        results["result"] = cloud.list_resources(type_name, identifier)

    if state in ("describe", "get"):
        if "read" not in handlers:
            module.exit_json(
                **results, msg=f"Resource type {type_name} cannot be read."
            )
        results["result"] = cloud.get_resource(type_name, identifier)

    if state == "present":
        results = cloud.present(
            type_name, identifier, params_to_set, create_only_params
        )

    if state == "absent":
        results["changed"] |= cloud.absent(type_name, identifier)

    module.exit_json(**results)


if __name__ == "__main__":
    main()
